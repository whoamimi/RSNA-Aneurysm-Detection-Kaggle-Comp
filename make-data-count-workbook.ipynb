{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Make Data Count Submission \n\nThis work makes use of [MiniSom](https://github.com/JustGlowing/minisom) \nby Giuseppe Vettigli (2018).\nExternal data source used for meta datasets: https://api.staging.crossref.org/swagger-ui/index.html#/Funders/get_funders__id__works","metadata":{}},{"cell_type":"code","source":"import os\n\n# Silence TF/XLA/absl chatter that spams STDERR on Kaggle\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"        # 0=all,1=INFO,2=WARNING,3=ERROR\nos.environ[\"ABSL_LOGGING_MIN_LOG_LEVEL\"] = \"3\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nTRAIN_Y_PATH: str = \"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\"\nTRAIN_DIR_PATH:  str = \"/kaggle/input/make-data-count-finding-data-references/train\"\nTEST_DIR_PATH:  str = \"/kaggle/input/make-data-count-finding-data-references/train\"\n\nMETA_PAPER_API = \"https://api.crossref.org/works/{doi}\"\nDEFAULT_SOURCE_TYPE = 'Unknown'\nMODEL_ID = \"all-MiniLM-L6-v2\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T18:06:14.175205Z","iopub.execute_input":"2025-08-23T18:06:14.175447Z","iopub.status.idle":"2025-08-23T18:06:14.180210Z","shell.execute_reply.started":"2025-08-23T18:06:14.175423Z","shell.execute_reply":"2025-08-23T18:06:14.179488Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install dependencies \n\n!pip install -U sentence-transformers\n!python -m sentence_transformers all-MiniLM-L6-v2\n!pip install -U pypdf\n!pip install pdfminer.six","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T18:06:14.180817Z","iopub.execute_input":"2025-08-23T18:06:14.181042Z","iopub.status.idle":"2025-08-23T18:08:06.250779Z","shell.execute_reply.started":"2025-08-23T18:06:14.181026Z","shell.execute_reply":"2025-08-23T18:08:06.250060Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting sentence-transformers\n  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 4.1.0\n    Uninstalling sentence-transformers-4.1.0:\n      Successfully uninstalled sentence-transformers-4.1.0\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-5.1.0\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755972462.038229      94 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755972462.096685      94 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/bin/python3: No module named sentence_transformers.__main__; 'sentence_transformers' is a package and cannot be directly executed\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.7.0)\nCollecting pypdf\n  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\nDownloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pypdf\n  Attempting uninstall: pypdf\n    Found existing installation: pypdf 5.7.0\n    Uninstalling pypdf-5.7.0:\n      Successfully uninstalled pypdf-5.7.0\nSuccessfully installed pypdf-6.0.0\nCollecting pdfminer.six\n  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (44.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\nDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pdfminer.six\nSuccessfully installed pdfminer.six-20250506\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Data Helpers and Utilities \n\nimport re\nimport io\nimport glob\nimport logging\nimport requests\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom pdfminer.high_level import extract_text\nfrom dataclasses import dataclass, field, asdict\nfrom typing import Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union, Any\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom sentence_transformers import SentenceTransformer\n\nlogger = logging.getLogger(\"kaggle_notebook\")\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter(\n    \"%(asctime)s | %(levelname)-8s | %(message)s\", \"%Y-%m-%d %H:%M:%S\"\n)\nhandler.setFormatter(formatter)\n\ndef _read_file_binary(path: str) -> bytes:\n    with open(path, \"rb\") as f:\n        return f.read()\n\n\ndef _clean_ws(text: str) -> str:\n    text = re.sub(r\"\\r\\n?\", \"\\n\", text)\n    text = re.sub(r\"[ \\t]+\", \" \", text)\n    text = re.sub(r\"\\n\\s*\\n\\s*\\n+\", \"\\n\\n\", text)  # collapse >2 blank lines\n    return text.strip()\n\n\ndef _pdf_to_text(path: str) -> str:\n    \"\"\"Extract text from PDF using pdfminer.six if available, else PyPDF2 as fallback.\"\"\"\n    # Try pdfminer.six (best quality)\n    try:\n        # Note: extract_text opens file internally; pass path.\n        text = extract_text(path) or \"\"\n        return _clean_ws(text)\n    except Exception:\n        pass\n\n    # Fallback: PyPDF2\n    try:\n        import PyPDF2  # type: ignore\n        text_chunks: List[str] = []\n        with open(path, \"rb\") as f:\n            reader = PyPDF2.PdfReader(f)\n            for pg in reader.pages:\n                try:\n                    s = pg.extract_text() or \"\"\n                except Exception:\n                    s = \"\"\n                if s:\n                    text_chunks.append(s)\n        return _clean_ws(\"\\n\\n\".join(text_chunks))\n    except Exception:\n        return \"\"\n\ndef _xml_to_text(path: str) -> str:\n    \"\"\"Parse XML with lxml if available, else ElementTree. Extracts title/abstract/body-ish text.\"\"\"\n    xml_bytes = _read_file_binary(path)\n\n    # Try lxml first (best for namespaces/xpaths).\n    try:\n        from lxml import etree  # type: ignore\n        parser = etree.XMLParser(recover=True, huge_tree=True)\n        root = etree.fromstring(xml_bytes, parser=parser)\n\n        # Common scholarly XML patterns (JATS-ish)\n        texts: List[str] = []\n\n        # title\n        titles = root.xpath(\"//article-title|//title-group//article-title|//title\")\n        titles = [t.text if isinstance(t, etree._Element) else str(t) for t in titles]\n        titles = [t for t in titles if t]\n        if titles:\n            texts.append(\"# \" + titles[0].strip())\n\n        # abstract\n        abs_nodes = root.xpath(\"//abstract//p|//Abstract//p|//abstract\")\n        for n in abs_nodes:\n            s = \"\".join(n.itertext()) if hasattr(n, \"itertext\") else str(n)\n            s = s.strip()\n            if s:\n                texts.append(s)\n\n        # body\n        body_nodes = root.xpath(\"//body//p|//sec//p|//Body//p\")\n        for n in body_nodes:\n            s = \"\".join(n.itertext()) if hasattr(n, \"itertext\") else str(n)\n            s = s.strip()\n            if s:\n                texts.append(s)\n\n        # fallback: all text\n        if not texts:\n            all_text = \" \".join(root.itertext())\n            texts = [all_text]\n\n        return _clean_ws(\"\\n\\n\".join(texts))\n\n    except Exception:\n        # Fallback to stdlib ElementTree\n        import xml.etree.ElementTree as ET\n\n        try:\n            root = ET.fromstring(xml_bytes)\n        except Exception:\n            return \"\"  # unreadable\n\n        def itxt(el):\n            try:\n                return \"\".join(el.itertext())\n            except Exception:\n                return el.text or \"\"\n\n        # Attempt similar sections by tag name\n        parts: List[str] = []\n        # naive title\n        for tag in (\"article-title\", \"title\"):\n            for n in root.iter(tag):\n                s = (n.text or \"\").strip()\n                if s:\n                    parts.append(\"# \" + s)\n\n        # abstract\n        for tag in (\"abstract\",):\n            for n in root.iter(tag):\n                s = itxt(n).strip()\n                if s:\n                    parts.append(s)\n\n        # paragraphs\n        for tag in (\"p\",):\n            for n in root.iter(tag):\n                s = itxt(n).strip()\n                if s:\n                    parts.append(s)\n\n        if not parts:\n            parts = [itxt(root)]\n\n        return _clean_ws(\"\\n\\n\".join([p for p in parts if p]))\n\n@dataclass\nclass Author:\n    family: Optional[str] = None\n    given: Optional[str] = None\n    literal: Optional[str] = None\n\n\n@dataclass\nclass Issued:\n    date_parts: List[List[int]] = field(default_factory=list)\n\n\n@dataclass\nclass DoiResponse:\n    type: str\n    id: str\n    categories: List[str]\n    author: List[Author]\n    issued: Issued\n    abstract: str\n    DOI: str\n    publisher: str\n    title: str\n    URL: str\n    copyright: str\n\n    @staticmethod \n    def parse_response(data: Dict[str, Any]):\n        authors = [Author(**a) for a in data.get(\"author\", [])]\n        issued = Issued(date_parts=data.get(\"issued\", {}).get(\"date-parts\", []))\n        return DoiResponse(\n            type=data.get(\"type\", \"\"),\n            id=data.get(\"id\", \"\"),\n            categories=data.get(\"categories\", []),\n            author=authors,\n            issued=issued,\n            abstract=data.get(\"abstract\", \"\"),\n            DOI=data.get(\"DOI\", \"\"),\n            publisher=data.get(\"publisher\", \"\"),\n            title=data.get(\"title\", \"\"),\n            URL=data.get(\"URL\", \"\"),\n            copyright=data.get(\"copyright\", \"\"),\n        )\n\n@dataclass\nclass Article:\n    article_id: str \n    text: str \n    extension: str \n    source: str = DEFAULT_SOURCE_TYPE\n    dataset_id: str | None = None \n    embedding: np.ndarray | None = None\n\n    @staticmethod\n    def fetch_meta_external(input_doi: str) -> dict | None:\n        url = META_PAPER_API.format(doi=input_doi)\n        \n        try:\n            r = requests.get(url)\n            return r.json()\n        except Exception as e: \n            logger.error(e)\n            return None\n\n    @staticmethod\n    def fetch_meta_doi(doi_url: str) -> DoiResponse | None:\n        try:\n            headers = {\"Accept\": \"application/vnd.citationstyles.csl+json\"}\n            r = requests.get(doi_url, headers=headers, timeout=30)\n            if r.status_code == 200:\n                result = r.json()\n                return DoiResponse.parse_response(result)\n                \n        except Exception as e: \n            logger.error(e)\n            return None\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:02:28.970277Z","iopub.execute_input":"2025-08-23T19:02:28.970772Z","iopub.status.idle":"2025-08-23T19:02:28.993954Z","shell.execute_reply.started":"2025-08-23T19:02:28.970753Z","shell.execute_reply":"2025-08-23T19:02:28.993220Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def load_train_dataset(model: SentenceTransformer):\n    \"\"\" Loads the dataset for training. \"\"\"\n    \n    targets = pd.read_csv(TRAIN_Y_PATH)\n    logger.info(f\"Dataset Labels: {targets['type'].unique()}\")\n    \n    for path in tqdm(Path(\"/kaggle/input\").rglob(\"*\"), desc=\"Loading Train datasets\"):\n        if path.parents[1].stem == 'train' and path.is_file():\n            info = {}\n            \n            ext = path.suffix\n            \n            if ext == '.pdf': \n                text = _pdf_to_text(str(path))\n            elif ext == '.xml': \n                text = _xml_to_text(str(path))\n\n            meta = targets[targets['article_id'] == path.stem]\n            \n            info['extension'] = ext \n            info['text'] = text \n            info['article_id'] = path.stem\n            info['embedding'] = model.encoder(info['text']) if text != '' else None\n            \n            if not meta.empty:\n                metas = meta.iloc[0].to_dict()\n                info[\"source\"] = metas.get(\"type\", DEFAULT_SOURCE_TYPE)\n                info[\"dataset_id\"] = metas.get(\"dataset_id\", None)\n            else:\n                logger.warning(\"No label metadata found for %s\", path.stem)\n\n            yield Article(**info)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T18:08:15.614734Z","iopub.execute_input":"2025-08-23T18:08:15.615233Z","iopub.status.idle":"2025-08-23T18:08:15.621330Z","shell.execute_reply.started":"2025-08-23T18:08:15.615212Z","shell.execute_reply":"2025-08-23T18:08:15.620659Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class DoiData(Dataset): \n    \"\"\" Doi Dataset handler. \n    Target types:\n    'Unknown': missing from train dataset\n    'Missing': missing from data - predefined in the dataset\n    'Primary' / 'Secondary': Main Data Referencing Labels\n    \"\"\"\n    \n    def __init__(self):\n        self.data = list(load_train_dataset())\n        self.model = SentenceTransformer(MODEL_ID)\n        \n        assert len(self.data) > 0, \"Empty dataset loaded to instance\"\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx: int): \n        if idx > len(self.data) or idx < 0:\n            raise ValueError('Index out of range.')\n            \n        article = self.data[idx]\n        emb = self.model.encode(\n            article.text,\n            convert_to_numpy=True,               # ensures np.ndarray (not torch)\n            normalize_embeddings=False           # set True if you want L2-normalized\n        )\n        assert emb.shape[0] == 384, f'Unexpected shape returned for encoded text: {emb.shape}'\n        \n        article.embedding = emb \n        # TODO: CONVERT TO X_train, y_train outputs\n        if meta := Article.fetch_meta_doi(article.dataset_id):\n            return {**asdict(article), **asdict(meta)}\n            \n        return asdict(article)\n        \nds = DoiData()\ncache_path = \"/kaggle/working/train_dataset.parquet\"\nds.build_cache(cache_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T18:08:15.622237Z","iopub.execute_input":"2025-08-23T18:08:15.622509Z","iopub.status.idle":"2025-08-23T19:02:28.874714Z","shell.execute_reply.started":"2025-08-23T18:08:15.622486Z","shell.execute_reply":"2025-08-23T19:02:28.874137Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"Loading Train datasets: 988it [54:04,  3.28s/it] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b183bd2fc93c42ad970ad78fffec2c69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4852de88059424c8ca9470fabac226e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b83086dfbaf84401b6aa524d9aa5a5e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bbea8ea7cfc4a48ae2f4f552d5ffd6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d412787aa1a4657a7bf76379668abd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2daaed3e85492583fe0c7264d5615d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea4cbea10764bb88fc2186b78c58f15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851e58f15a234a7cb428c25587424918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2d18ed016f444ab2ffe04418a6b2f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172861c7cfee471a9ed1161ba0a9b993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4ebaac881846f896c20f5058331f73"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df = pd.DataFrame(ds.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:02:28.875484Z","iopub.execute_input":"2025-08-23T19:02:28.875695Z","iopub.status.idle":"2025-08-23T19:02:28.889436Z","shell.execute_reply.started":"2025-08-23T19:02:28.875677Z","shell.execute_reply":"2025-08-23T19:02:28.888862Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.to_parquet('/kaggle/temp/train_dataset.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:02:28.891371Z","iopub.execute_input":"2025-08-23T19:02:28.891582Z","iopub.status.idle":"2025-08-23T19:02:28.966638Z","shell.execute_reply.started":"2025-08-23T19:02:28.891564Z","shell.execute_reply":"2025-08-23T19:02:28.965830Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                          article_id  \\\n0    10.1590_1678-4685-gmb-2018-0055   \n1               10.1021_jacs.2c06519   \n2          10.1107_s2056989015019891   \n3          10.1186_s12881-019-0773-3   \n4                  10.3762_bjoc.8.42   \n..                               ...   \n919        10.1590_1414-431x20198292   \n920    10.1080_15476286.2016.1232238   \n921     10.1371_journal.pntd.0005385   \n922     10.1371_journal.pone.0170126   \n923        10.1186_s12864-019-5872-1   \n\n                                                  text extension   source  \\\n0    # Mitochondrial genomes of genus\\n\\nAbstractTh...      .xml  Missing   \n1    # Identification of Oxidation\\nState +1 in a M...      .xml  Primary   \n2    # Crystal structure of 1,1,2,2-tetra­methyl-1,...      .xml  Missing   \n3    # A pharmacogenetic study of patients with sch...      .xml  Missing   \n4    # Synthesis of mesomeric betaine compounds wit...      .xml  Missing   \n..                                                 ...       ...      ...   \n919  Brazilian Journal of Medical and Biological Re...      .pdf  Missing   \n920  RNA Biology\\n\\nISSN: 1547-6286 (Print) 1555-85...      .pdf  Missing   \n921  RESEARCH ARTICLE\\n\\nAdvances in neglected trop...      .pdf  Primary   \n922  RESEARCH ARTICLE\\n\\nNovel Porcine Epidemic Dia...      .pdf  Missing   \n923  Shen et al. BMC Genomics (2019) 20:467 \\nhttps...      .pdf  Missing   \n\n                                          dataset_id embedding  \n0    https://doi.org/10.6084/m9.figshare.11609370.v1      None  \n1           https://doi.org/10.25377/sussex.21184705      None  \n2                   https://doi.org/10.5517/cc1k2lx4      None  \n3        https://doi.org/10.6084/m9.figshare.7975355      None  \n4           https://doi.org/10.5517/ccdc.csd.ccy1n8w      None  \n..                                               ...       ...  \n919   https://doi.org/10.6084/m9.figshare.8324420.v1      None  \n920      https://doi.org/10.6084/m9.figshare.3830103      None  \n921              https://doi.org/10.5061/dryad.72v34      None  \n922                                         KU363060      None  \n923   https://doi.org/10.6084/m9.figshare.8245019.v1      None  \n\n[924 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>text</th>\n      <th>extension</th>\n      <th>source</th>\n      <th>dataset_id</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.1590_1678-4685-gmb-2018-0055</td>\n      <td># Mitochondrial genomes of genus\\n\\nAbstractTh...</td>\n      <td>.xml</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.6084/m9.figshare.11609370.v1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.1021_jacs.2c06519</td>\n      <td># Identification of Oxidation\\nState +1 in a M...</td>\n      <td>.xml</td>\n      <td>Primary</td>\n      <td>https://doi.org/10.25377/sussex.21184705</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.1107_s2056989015019891</td>\n      <td># Crystal structure of 1,1,2,2-tetra­methyl-1,...</td>\n      <td>.xml</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.5517/cc1k2lx4</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.1186_s12881-019-0773-3</td>\n      <td># A pharmacogenetic study of patients with sch...</td>\n      <td>.xml</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.6084/m9.figshare.7975355</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.3762_bjoc.8.42</td>\n      <td># Synthesis of mesomeric betaine compounds wit...</td>\n      <td>.xml</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.5517/ccdc.csd.ccy1n8w</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>10.1590_1414-431x20198292</td>\n      <td>Brazilian Journal of Medical and Biological Re...</td>\n      <td>.pdf</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.6084/m9.figshare.8324420.v1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>920</th>\n      <td>10.1080_15476286.2016.1232238</td>\n      <td>RNA Biology\\n\\nISSN: 1547-6286 (Print) 1555-85...</td>\n      <td>.pdf</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.6084/m9.figshare.3830103</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>921</th>\n      <td>10.1371_journal.pntd.0005385</td>\n      <td>RESEARCH ARTICLE\\n\\nAdvances in neglected trop...</td>\n      <td>.pdf</td>\n      <td>Primary</td>\n      <td>https://doi.org/10.5061/dryad.72v34</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>922</th>\n      <td>10.1371_journal.pone.0170126</td>\n      <td>RESEARCH ARTICLE\\n\\nNovel Porcine Epidemic Dia...</td>\n      <td>.pdf</td>\n      <td>Missing</td>\n      <td>KU363060</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>10.1186_s12864-019-5872-1</td>\n      <td>Shen et al. BMC Genomics (2019) 20:467 \\nhttps...</td>\n      <td>.pdf</td>\n      <td>Missing</td>\n      <td>https://doi.org/10.6084/m9.figshare.8245019.v1</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>924 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.to_parquet('/kaggle/working/train_dataset.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:12:29.730090Z","iopub.execute_input":"2025-08-23T19:12:29.730398Z","iopub.status.idle":"2025-08-23T19:12:30.374646Z","shell.execute_reply.started":"2025-08-23T19:12:29.730373Z","shell.execute_reply":"2025-08-23T19:12:30.374059Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/train_data.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:14:52.516572Z","iopub.execute_input":"2025-08-23T19:14:52.517288Z","iopub.status.idle":"2025-08-23T19:14:53.984005Z","shell.execute_reply.started":"2025-08-23T19:14:52.517254Z","shell.execute_reply":"2025-08-23T19:14:53.983409Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# TEST URL EXTRACTION \n\nsamples = [\n    {\n        \"dataset_id\": \"https://doi.org/10.1098/rspb.2016.1151\",\n        \"data\": [\"https://doi.org/10.5061/dryad.6m3n9\"],\n        \"in_text_span\": \"The data we used in this publication can be accessed from Dryad at doi:10.5061/dryad.6m3n9.\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1098/rspb.2018.1563\",\n        \"data\": [\"https://doi.org/10.5061/dryad.c394c12\"],\n        \"in_text_span\": \"Phenotypic data and gene sequences are available from the Dryad Digital Repository: http://dx.doi.org/10.5061/dryad.c394c12\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1534/genetics.119.302868\",\n        \"data\": [\"https://doi.org/10.25386/genetics.11365982\"],\n        \"in_text_span\": \"The authors state that all data necessary for confirming the conclusions presented in the article are represented fully within the article. Supplemental material available at figshare: https://doi.org/10.25386/genetics.11365982.\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.1038/sdata.2014.33\",\n        \"data\": [\"GSE37569\", \"GSE45042\", \"GSE28166\"],\n        \"in_text_span\": \"Primary data for Agilent and Affymetrix microarray experiments are available at the NCBI Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) under the accession numbers GSE37569, GSE45042 , GSE28166\",\n        \"citation_type\": \"Primary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.12688/wellcomeopenres.15142.1\",\n        \"data\": [\"pdb 5yfp\"],\n        \"in_text_span\": \"Figure 1. Evolution and structure of the exocyst... All structural images were modelled by the authors from PDB using UCSF Chimera.\",\n        \"citation_type\": \"Secondary\",\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.3389/fimmu.2021.690817\",\n        \"data\": [\"E-MTAB-10217\", \"PRJE43395\"],\n        \"in_text_span\": \"The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found below: https://www.ebi.ac.uk/arrayexpress/, E-MTAB-10217 and https://www.ebi.ac.uk/ena, PRJE43395.\",\n        \"citation_type\": \"Secondary\",\n    },\n]\n\nimport re\nfrom typing import Optional\n\n# -------- DOI detection --------\ndef is_doi(s: str) -> bool:\n    \"\"\"Check if a string looks like a DOI identifier.\"\"\"\n    s = s.strip()\n    return bool(\n        re.match(r\"^(https?://(dx\\.)?doi\\.org/)?10\\.\\d{4,9}/\\S+$\", s, flags=re.I)\n        or s.lower().startswith(\"doi:\")\n    )\n\ndef doi_to_url(s: str) -> Optional[str]:\n    \"\"\"Normalize a DOI string into https://doi.org/... form.\"\"\"\n    s = s.strip()\n    # strip leading \"doi:\" or \"http(s)://doi.org/\"\n    s = re.sub(r\"^(?i)(doi:|https?://(dx\\.)?doi\\.org/)\", \"\", s)\n    m = re.match(r\"^(10\\.\\d{4,9}/\\S+)$\", s)\n    if m:\n        return \"https://doi.org/\" + m.group(1)\n    return None\n\n# -------- Accession detection --------\ndef is_accession(s: str) -> bool:\n    \"\"\"Check if a string looks like an accession ID (non-DOI dataset identifier).\"\"\"\n    s = s.strip()\n    return (\n        re.match(r\"^GSE\\d+$\", s, re.I)          # GEO\n        or re.match(r\"^E-(MTAB|MEXP|GEO)-\\d+$\", s, re.I)  # ArrayExpress\n        or re.match(r\"^PRJ\\w+\\d+$\", s, re.I)   # ENA/NCBI BioProject\n        or re.match(r\"^(pdb\\s+)?[0-9A-Za-z]{4}$\", s, re.I)  # PDB\n    ) is not None\n\ndef accession_to_url(s: str) -> Optional[str]:\n    \"\"\"Map a known accession ID into the correct repository URL.\"\"\"\n    s = s.strip()\n\n    # GEO\n    if re.match(r\"^GSE\\d+$\", s, re.I):\n        return f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={s}\"\n\n    # ArrayExpress\n    if re.match(r\"^E-(MTAB|MEXP|GEO)-\\d+$\", s, re.I):\n        return f\"https://www.ebi.ac.uk/arrayexpress/experiments/{s}\"\n\n    # ENA/BioProject\n    if re.match(r\"^PRJ\\w+\\d+$\", s, re.I):\n        return f\"https://www.ebi.ac.uk/ena/browser/view/{s}\"\n\n    # PDB\n    if s.lower().startswith(\"pdb \"):\n        pdb_id = s.split()[1]\n        return f\"https://www.rcsb.org/structure/{pdb_id.lower()}\"\n    if len(s) == 4 and re.match(r\"^[0-9A-Za-z]{4}$\", s):\n        return f\"https://www.rcsb.org/structure/{s.lower()}\"\n\n    return None\n\nexamples = [\n    \"10.1371/journal.pone.0303785\",\n    \"https://doi.org/10.5061/dryad.r6nq870\",\n    \"doi:10.6084/m9.figshare.11609370.v1\",\n    \"GSE12345\",\n    \"E-MEXP-568\",\n    \"E-MTAB-10217\",\n    \"PRJE43395\",\n    \"PDB 1Y2T\",\n    \"5YFP\",\n]\n\nfor ex in examples:\n    if is_doi(ex):\n        print(ex, \"-> DOI:\", doi_to_url(ex))\n    elif is_accession(ex):\n        print(ex, \"-> Accession:\", accession_to_url(ex))\n    else:\n        print(ex, \"-> Unknown\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:02:29.177321Z","iopub.execute_input":"2025-08-23T19:02:29.177628Z","iopub.status.idle":"2025-08-23T19:02:29.284843Z","shell.execute_reply.started":"2025-08-23T19:02:29.177593Z","shell.execute_reply":"2025-08-23T19:02:29.283679Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1015683050.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_doi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-> DOI:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoi_to_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_accession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-> Accession:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccession_to_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1015683050.py\u001b[0m in \u001b[0;36mdoi_to_url\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# strip leading \"doi:\" or \"http(s)://doi.org/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^(?i)(doi:|https?://(dx\\.)?doi\\.org/)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^(10\\.\\d{4,9}/\\S+)$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/__init__.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/__init__.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    292\u001b[0m                   \u001b[0;34m\"Don't use it.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                   DeprecationWarning)\n\u001b[0;32m--> 294\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/_compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/_parser.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    465\u001b[0m                            not nested and not items))\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/re/_parser.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    848\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# global flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msubpattern\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                             raise source.error('global flags not at the start '\n\u001b[0m\u001b[1;32m    851\u001b[0m                                                \u001b[0;34m'of the expression'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                                                source.tell() - start)\n","\u001b[0;31merror\u001b[0m: global flags not at the start of the expression at position 1"],"ename":"error","evalue":"global flags not at the start of the expression at position 1","output_type":"error"}],"execution_count":10}]}